# Критерий нормальности Колмогорова-Смирнова

## Постановка задачи

Мы исследуем отклонение распределения гистограммы эмпирического распределения от теоретического или другого распределения. Прежде всего нас интересует поиск отклонения от нормального распределения, заданного функцией CDF — кумулятивной функцией распределения вероятности.

1. Мы хотим доказать или опровергнуть гипотезу нормального распределения положительных исходов $H_0$. 
2. Мы исходим из предположения, что распределение с большим фиксированным временем накопления может оказаться ниже, чем распределение с динамическим управлением заданиями (окном).
3. При нормальном законе распределения мы планируем сформулировать критерий, который бы подходил для раннего выявления нерабочих режимов оборудования генерации случайных чисел. 

Мы добавляем в ПО возможность анализа статистических данных и проверки гипотезы о нормальном распределении вероятности при данной выборке.

Нормальный закон распределения плотности вероятности будет выражаться в терминах математического ожидания и дисперсии. Для математической оценки отклонения используются различные критерии, среди которых выделяется критерий Колмогорова-Смирнова.

![Cumulative distribution function for the normal distribution](https://upload.wikimedia.org/wikipedia/commons/c/ca/Normal_Distribution_CDF.svg)

CDF (Кумулятивная функция распределения для нормального распределения вероятности) — это функция, которая показывает вероятность того, что случайная величина $X$ примет значение меньше или равное заданному числу $x$, т.е. $P(X \le x)$. CDF является возрастающей функцией, начинается с 0 и достигает 1, преобразуя функцию плотности вероятности (PDF) в накопленное значение вероятности до точки $x$.

Положим, что $X$ распределена _нормально_. Тогда CDF для $X$ задается формулой:
```math
F(t; \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} \int_{-\infty}^{t} \exp\left( -\frac{(x - \mu)^2}{2\sigma^2} \right) \, dx.
```
Здесь параметр $\mu$ — это математическое ожидание распределения, а $\sigma$ — его стандартное отклонение.

Положим, что $X$ распределена _биномиально_. Тогда CDF для $X$ задается формулой:
```math
F(k; n, p) = \Pr(X \le k) = \sum_{i=0}^{\lfloor k \rfloor} \binom{n}{i} p^i (1-p)^{n-i}.
```
Здесь $p$ — вероятность успеха, функция описывает дискретное распределение числа успехов в последовательности из $n$ независимых экспериментов, а $\lfloor k \rfloor$ — "пол" под $k$, т.е. наибольшее целое число, меньшее или равное $k$.

Рекомендации по анализу статистики представлены в ГОСТ Р 50.1.033-2001 и ГОСТ Р 50.1.037-2002:

- [Р 50.1.033-2001] РЕКОМЕНДАЦИИ ПО СТАНДАРТИЗАЦИИ. Прикладная статистика. Правила проверки согласия опытного распределения с теоретическим. Часть I. Критерии типа хи-квадрат.
- [Р 50.1.037-2002] РЕКОМЕНДАЦИИ ПО СТАНДАРТИЗАЦИИ. Прикладная статистика. Правила проверки согласия опытного распределения с теоретическим. Часть II. Непараметрические критерии (рассматривает критерий Колмогорова и критерий Смирнова).

См. также:
- [Kolmogorov–Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)
- [Normality test](https://en.wikipedia.org/wiki/Normality_test)

## Критерий согласия Колмогорова

Применение критерия согласия А. Н. Колмогорова в практике осложняется следующими обстоятельствами. Для сопоставления функций эмпирического и теоретического распределений необходимо знать значения математического ожидания и среднего квадратического отклонения наблюдаемой случайной величины, которые обычно неизвестны.

В 1933 г. А. Н. Колмогоров доказал важную теорему: если функция $F(x)$ непрерывна, то при $n \to \infty$ вероятность события $\sup_x |F_n(x) - F(x)| < t / \sqrt{n}$ стремится к распределению Колмогорова.

**Формулировка**

Пусть $X_1, \ldots, X_n$ — выборка объёма $n$, порождённая случайной величиной, которая задаётся непрерывной функцией распределения $F(x)$. Пусть $F_n(x)$ — эмпирическая функция распределения. Тогда $\sqrt{n} \sup_{x \in \mathbb{R}} |F_n(x) - F(x)| \to K$ по распределению при $n \to \infty$, где $K$ — случайная величина, имеющая распределение Колмогорова.

*Неформально говорят, что скорость сходимости эмпирической функции распределения к её теоретическому аналогу имеет порядок $1/\sqrt{n}$.

Обозначим нулевую гипотезу $H_0$ как гипотезу о том, что выборка подчиняется распределению $F(x) \in C^1(\mathbb{X})$. Тогда по теореме Колмогорова для введённой статистики справедливо:
```math
\forall t > 0 \colon \lim_{n \to \infty} P(\sqrt{n} D_n \leqslant t) = K(t) = \sum_{j=-\infty}^{+\infty} (-1)^j e^{-2j^2 t^2} = \theta_4(e^{-2t^2}),
```
где $D_n = \sup_x |F_n(x) - F(x)|$.

**Теорема Смирнова**

Пусть $F_{1,n}(x)$, $F_{2,m}(x)$ — эмпирические функции распределения, построенные по независимым выборкам объёмом $n$ и $m$ случайной величины $\xi$. Тогда, если $F(x) \in C^1(\mathbb{X})$, то
```math
\forall t > 0 \colon \lim_{n,m \to \infty} P\left( \sqrt{\frac{nm}{n+m}} D_{n,m} \leqslant t \right) = K(t) = \sum_{j=-\infty}^{+\infty} (-1)^j e^{-2j^2 t^2},
```
где $D_{n,m} = \sup_x |F_{1,n}(x) - F_{2,m}(x)|$.

Теорема Смирнова позволяет построить критерий для проверки двух выборок на однородность.

## Критерий согласия Кёйпера (KS_Kuiper)

> Изначально, я смотрел в код проекта `Dieharder` (набор тестов для проверки ГПСЧ), где применяется ряд вариантов теста KS, включая тест Кёйпера. В этой связи, следует упомянуть критерий. Теорема Колмогорова порождает много вариантов оценки статистики. Многие методы в прикладной статистике кажутся математически не обоснованными. Например, применение метода для нормального распределения при условии, что в ядре операции выполняется сравнение с линейной функцией - недопустимо. 

Мы отдельно рассматриваем левые и правые отклонения, относительно нормального распределения $F(x,\theta)$, $D_{n}^{+}$ и $D_{n}^{-}$. В критерии Кёйпера используется статистика вида: 
$V_{n}=D_{n}^{+}+D_{n}^{-}$.

Критерий согласия Кёйпера (Купера) является вариантом критерия согласия Колмогорова и был предложен для проверки простых гипотез о принадлежности анализируемой выборки полностью известному закону, то есть для проверки гипотез вида 
$H_{0}:F_{n}(x)=F(x,\theta )$ с известным вектором параметров теоретического закона.

Для однородного распределения предлагается используется сравнение с линейной кумулятивной функцией однородного распределения $F(x)=i/n$
```math
D_{n}^{+}=\max {\left({\frac {i}{n}}-F(x_{i})\right)},   
```
```math
D_{n}^{-}=\max {\left(F(x_{i})-{\frac {i-1}{n}}\right)}~, 
 ~~i={1,...n} ,  
```
$n$ — объём выборки, $x_{1},x_{2},...,x_{n}$ — упорядоченные по возрастанию элементы выборки.

## Критерий Крамера — Мизеса — Смирнова

$\omega^2$-статистика Мизеса. Cramér–von Mises test

Базовая идея - рассмотрение интеграла отклонения эмпирической кумулятивной функции от непрерывной кумулятивной функции нормального распределения.
```math
\omega ^{2}=\int _{-\infty }^{\infty }[F_{n}(x)-F^{*}(x)]^{2}\,\mathrm {d} F^{*}(x)
```

Далее почему-то вместо кумулятивной функции нормального распределения возникает сравнение с линейной функцией (кумулятивной функцией однородного распределения). 

```math
S=n\omega ^{2}={\frac {1}{12n}}+\sum _{i=1}^{n}\left[F_{n}(x_{i}) - {\frac {2i-1}{2n}}\right]^{2}.
```
> Магия числа 12 мне не ясна. Очевидно это какая-то поправка, для согласования критерия при малых $n$, связанная со способом дискретизации данных.

## Критерий Андерсона-Дарлинга

$\Omega^2$-статистика Мизеса. 

The Anderson–Darling and Cramér–von Mises statistics belong to the class of quadratic EDF statistics (tests based on the empirical distribution function).[2] If the hypothesized distribution is 
$F$, and empirical (sample) cumulative distribution function is 
$F_{n}$, then the quadratic EDF statistics measure the distance between 
$F$ and $F_{n}$ by
```math
\Omega^{2}=n\int _{-\infty }^{\infty }{\left[F_{n}(x)-F(x)\right]}^{2}\,w(x)\,dF(x),
```
где $n$ число элементов выборки, $w(x)$ - весовая функция. 

В случае 
$w(x)=1$, используется статистика Крмаера-Мизеса (Cramér–von Mises). Тест Андерсона-Дарлинга (Anderson–Darling) (1954) основан на квадратичной дистанции
```math
\Omega^{2}=n\int _{-\infty }^{\infty }{\frac {{\left[F_{n}(x)-F(x)\right]}^{2}}{F(x)\left(1-F(x)\right)}}\,dF(x),
```
с весовой функцией 
$w(x)={\left[F(x)\left(1-F(x)\right)\right]}^{-1}$. В таком виде тест может быть более чувствителен к отклонениям на краях распределения. 

Формулу можно упростить используя асимптотику, для случая однородного распределения:

```math
S_{\Omega }=-n-2\sum _{i=1}^{n}\left\{{\frac {2i-1}{2n}}\ln(F(x_{i},\theta ))+\left(1-{\frac {2i-1}{2n}}\right)\ln(1-F(x_{i},\theta ))\right\},
```

где $n$ — объём выборки, 
$x_{1},x_{2},...,x_{n}; — упорядоченные по возрастанию элементы выборки.

* Anderson T. W., Darling D. A. Asymptotic theory of certain «goodness of fit» criteria based on stochastic processes // Ann. Math. Statist. — 1952. — V. 23. — P. 193—212.
* Anderson T. W., Darling D. A. A test of goodness of fit // J. Amer. Stist. Assoc., 1954. — V. 29. — P. 765—769.

> Хочется упростить статистику применительно к однородному распределению. Кумулятивная функция однородного распределения $F(x) = x$. Для анализа мы рассматриваем квадратичное отклонение от непрерывного распределения $F(x)$. И это должно напоминать среднеквадратичное отклонение. В идеале надо выражать нормировку отклонения в терминах функции распределения вероятности. И таким образом, мы приходим к критерию Пирсона. Следовало бы начать изложение с критерия Пирсона. Или вывести формулу критерия из формулы Байеса для полной вероятности. Далее рассмотреть асимптотику приводящую к использованию логарифмов в критериях нормальности, подобно тому как логарифмы возникают в машинном обучении.


## Xи-квадрат критерий Пирсона

Данный раздел, следует начать с математической статистики.\
[1] Б. А. СЕВАСТЬЯНОВ КУРС ТЕОРИИ ВЕРОЯТНОСТЕЙ И МАТЕМАТИЧЕСКОЙ СТАТИСТИКИ

{дописать}

## Тест Шапиро-Уилка

Тест Шапиро-Уилка — это популярный статистический метод для проверки, насколько выборка данных соответствует нормальному (гауссову) распределению, особенно эффективный для малых и средних выборок (до 2000 наблюдений). Он сравнивает упорядоченные значения выборки с ожидаемыми значениями нормального распределения, возвращая p-value: если p > 0.05, данные считаются нормальными; если p ≤ 0.05, нормальность отвергаем (отклоняем нулевую гипотезу).

Основные моменты:
- **Цель**: Определить, принадлежат ли данные нормальному распределению.
- **Гипотезы**: $H_0$ (Нулевая гипотеза): Данные распределены нормально. $H_1$ (Альтернативная): Данные не распределены нормально.
- **Принцип работы**: Основан на сравнении квантилей выборки с квантилями идеального нормального распределения. Статистика теста $W$ вычисляется как:
```math
W = \frac{\left( \sum_{i=1}^n a_i x_{(i)} \right)^2}{\sum_{i=1}^n (x_i - \bar{x})^2},
```
где $x_{(i)}$ — упорядоченные значения выборки, $a_i$ — коэффициенты, зависящие от $n$.
- **Интерпретация p-value (уровень значимости)**:
  - p-value > 0.05: Нет оснований отвергать $H_0$, данные можно считать нормальными.
  - p-value ≤ 0.05: Отвергаем $H_0$, данные значительно отличаются от нормального распределения.
- **Преимущества**: Считается одним из наиболее мощных тестов для проверки нормальности, особенно хорош для небольших выборок.
- **Ограничения**: Для очень больших выборок (>5000) рекомендуется использовать другие тесты, такие как тест Андерсона-Дарлинга.

См. также: [Shapiro–Wilk test](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test).

## Дополнительные критерии нормальности

Помимо упомянутых, существуют другие тесты на нормальность:
- **Тест Андерсона-Дарлинга**: более чувствительная к отклонениям на краях распределения.
- **Тест Лиллиефорса**: Модификация Колмогорова-Смирнова для случаев, когда параметры распределения оцениваются по выборке.
- **Тест Жарке-Бера**: Основан на асимметрии и эксцессе, эффективен для больших выборок.
- **Критерий хи-квадрат (Pearson)**: Для проверки согласия с любым распределением, включая нормальное, требует дискретизации данных.

## Криптографические генераторы Hash-DRNG и CTR-DRNG

[[NIST SP 800-90Ar1](https://doi.org/10.6028/NIST.SP.800-90Ar1)] Recommendation for Random Number Generation Using Deterministic Random Bit Generators.

Национальный стандарт NIST предлагает два варианта криптографических генераторов:
1. использовать в качестве основы хэш-функцию типа SHA256 или SHA3.
2. использовать блочный шифр AES в режиме CTR.

Обозначим общую идею использования криптографической хэш-функции в режиме Hash-DRNG. 
Оговорка. В SHA3 функция KECCAK может использоваться в режиме генерации потока бит (SPONGE-SQUEEZE алгоритм - отжимание губки), см SHAKE. В SHA2 хэш-функция может применяться по-блочно. Для генерации используется хэш функция в режиме генерации потока бит,заданной длины `returned_bits = HashGen(bit_len, V)`. Аргументом является предыдущее состояние (`V`). Новое состояние `H = Hash(V); V = V+H+C+Seed`- это рандомизация счетчика `C`, состояния `V` и `Seed`, с использованием той же хэш-функции.

К генератором случайных чисел (PRNG) можно применить требования:
1. Функция перебора состояний без повторов с псевдослучайным выходом.
2. Функция рандомизации выходных значений для заданной длины (бит).

На примере алгоритма MWC64x:

Состояние представлено, как пара чисел {x,c}: $S = (x+\beta c) \bmod P$, где $P = A\beta-1$, $\beta=2^s$.
1. Итерация выполняется на математической операции: $S = S\beta \bmod P$.
2. Рандомизация выходного значения: $x \oplus c$;


## Пакеты тестирования ГПСЧ

Существуют пакеты тестирования генераторов, которые позволяют сравнить в различных тестах. На практике используют тесты вроде NIST SP 800-22 (dieharder, TestU01) для проверки равномерности вывода бит генератора. По результатам теста генератор принимается нормальным или отвергается.

**NIST, TestU01 и Dieharder**

Сборка пакета тестирования TestU01 под GNU/Linux:
```sh
$ mkdir TestU01
$ cd TestU01
$ curl -OL http://simul.iro.umontreal.ca/testu01/TestU01.zip
$ unzip TestU01.zip
$ export basedir=`pwd`
$ cd TestU01-1.2.3/
$ ./configure --prefix="$basedir"
$ make -j 8
$ make -j 8 install
$ cd ../
$ mkdir lib-so
$ mv lib/*.so lib-so/.
$ gcc -std=c99 -Wall -O3 -o test-xoroshift.c test-xoroshift.c -Iinclude -Llib -ltestu01 -lprobdist -lmylib -lm
```

Для примера приведу результаты тестирования [Xoroshiro64*](test/test-xoroshiro64.txt) и [MWC64x](test/test-mwc64x.txt). 

```c 
/* тест MWC64x с использованием библиотеки TestU01 */
#include "TestU01.h"
#define A1 0xFFFEB81BuLL
static uint64_t state[1]={~0};
static uint32_t mwc64x(void) {
    uint64_t x = state[0];
    state[0] = A1*(uint32_t)(x) + (x>>32);
    return x^(x>>32);
}
int main()
{
    // Create TestU01 PRNG object for our generator
    unif01_Gen* gen = unif01_CreateExternGenBits("MWC64x", mwc64x);
    // Run the tests.
    bbattery_SmallCrush(gen);
    // Clean up.
    unif01_DeleteExternGenBits(gen);
    return 0;
}
```
Заметим, что в метод MWC64 добавлена операция XOR: `x ^ (x>>32)`. Я бы назвал это словом "рандомизатор" или "скрамблер", эта операция позволяет улучшить прохождение некоторых тестов. С той же целью, в метод `Xoroshiro64` добавлено умножение результата итерации на большое простое число. Авторы метода [xoroshiro](https://prng.di.unimi.it/) предлагают несколько таких "рандомизаторов", отчего алгоритмы отмечаются звездочками и плюсиками. 

Для тестирования и сравнения генераторов предлагают методику *Hamming–Weight Dependencies* [HWD](https://prng.di.unimi.it/hwd.php)

Для улучшения прохождения тестов авторы рекомендуют использовать старшие биты выхода генератора при переводе в вещественные числа.

Метод, который реализует этот тезис выглядит следующим образом
```c
float to_float(uint32_t x) {
    return (x>>8)*0x1.p-24f;
}
double to_double(uint64_t x) {
    return (x>>11)*0x1.p-53;
}
```
Аналогично, в наших тестах при работе с MWC64 мы использовали преобразование
```c
/* преобразование чисел в формат float32 дает распределение [0,1) */
static inline float u64_float(uint64_t x) {
	return ((uint32_t)((x>>32) ^ (x&0xFFFFFFFFU)) >> 8) * 0x1.0p-24f;
}
```

Пакет TastU01 предлагает _два_ метода инициализации и использования генератора. Первый вариант мы протестировали - он на выходе дает значение 32 бита на итерацию. Второй вариант работает в вещественных числах double и задает функцию генератора, как `double(*gen)()`:
```c
double uniformX () {
    return (((uint64_t)mwc64_next()<<21))*0x1.0p-53;
}
int main() {
    unif01_Gen* gen = unif01_CreateExternGen01("MWC64x-U[0,1)", uniformX);
    bbattery_SmallCrush(gen);
    return 0;
}
```
По ссылке представлены результаты теста [MWC64x](test/testu01-mwc64.txt) в режиме генератора однородного распределения U(0,1). Для сравнения привожу результаты теста [Xoroshiro64*](test/testu01-xoroshiro64.txt) при тех же условиях.

## Генераторы последовательности псевдослучайных чисел с нормальным распределением

Тестовая задача - определить нормальность распределения полученного при использовании генераторов ГПСЧ. Отправная точка - построение гистограммы эмпирического распределения и сравнение с гистограммой нормального распределения при $n \to \infty$. 

![Сравнение эмпирического распределения, полученного с использованием MWC64, и нормального распределения](images/gaussian.png)

Гистограмма получена при накоплении результатов с использованием нормального распределения от генератора MWC64. Нормальное распределение получается из однородного с использованием [преобразования Бокса-Мюллера](Gaussian.md).

**Рекомендация**: если мы тестируем нормальность после преобразования uniform → normal, Anderson–Darling обычно предпочтительнее KS/Lilliefors. KS тест выделяет максимальное отклонение, в то время как AD считает суммарное отклонение с учетом весовой функции. 

## Разработка алгоритма

Мы хотим сформулировать алгоритм, который применяет принципы выявления гиперплоскостей в многомерном распределении. Пока что существует только концепция эксплуатирующая идею многомерного способа разложения статистики. В наших тестах мы использовали 2D разложения статистики "салфетки", на которых могут проявляться сетки и полосы при подборе периода. 
Наш подход - [графические тесты последовательностей](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%BF%D1%81%D0%B5%D0%B2%D0%B4%D0%BE%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D1%8B%D1%85_%D0%BF%D0%BE%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9). При наличии полос и периодических структур, может использоваться Фурье преобразование.

Общая идея графического теста - представление разложения на плоскости или в единичном кубе и поиск вектора нормали к гиперплоскости, в которой проявляется периодическая структура. Это можно представить методом поворота единичного кубика под углом, где проекция на плоскость имеет периодическую структуру.

![Пример распределения на плоскости](images/photo_2026-01-22_14-32-05.jpg)

Рис. 1 Вывод статистики на плоскости, тест `MWC32` c параметром `A=0xFF00`. Выполнен подбор периода.

![Пример распределения в единичном кубе](images/photo_2026-01-22_14-31-27.jpg)

Одна из идей тестирования с ограниченной областью применения предлагается [спектральным тестом Д.Кнута](#). Область применения - линейные конгруэнтные генераторы. 

## Ключевые концепции алгоритма

1. **Представление статистических данных в форме тензора**: Данные — это тензор размерности $N \times M \times K \times \dots$ (например, 3D-тензор для событий по категориям). Это позволяет моделировать многомерные зависимости.
2. **Перестановка (permutation)**: Мы предполагаем использование операций над тензором: перестановки, группировки и нормировки. Рассматриваем возможность проецирования на гиперплоскость. Задача — найти гиперплоскость, на которой данные будут представлены в 2D и обладать контрастным распределением (например, с помощью методов PCA или UMAP/t-SNE для снижения размерности).
3. **Группировка блоков (folding)**: Разбиваем тензор на блоки и агрегируем их (сумма, среднее, максимум и т.д.), имитируя "складывание салфетки". Это помогает выявить скрытые паттерны.
4. **Выявление паттернов**: После каждой операции проверяем распределение в полученной матрице на отклонение от нормальности. Используем:
   - Статистические тесты (например, тест Шапиро-Уилка для нормальности; тест Колмогорова-Смирнова).
   - Визуализацию (гистограммы, 2D-heatmaps, QQ-графики) для выявления "узоров"/"водяных знаков".
   - Метрики отклонения: kurtosis (эксцесс), skewness (асимметрия), при сравнении с нормальным распределением.
5. **Итеративный поиск**: Перебираем комбинации перестановок и группировок, чтобы найти конфигурацию с наибольшим отклонением. Для оптимизации можно использовать генетические алгоритмы или градиентный спуск.

*Дополнение*: Алгоритм можно расширить на машинное обучение, интегрируя автоэнкодеры (см AutoEncoder и LDA) для выявления аномалий в распределениях. Это позволит автоматизировать раннее выявление нерабочих режимов оборудования.
* Linear Discriminant Analysis (LDA)

Рекомендация (для 2D-визуализации)
1. Есть метки классов + линейная разделимость: LDA → почти всегда лучший старт
2. Есть метки, но данные нелинейные: LDA → UMAP/t-SNE → AutoEncoder 
3. Нет меток, данные табличные: PCA → UMAP → Vanilla / Denoising AE
4. Нет меток, изображения/эмбеддинги: Convolutional-AE / ViT-AE → UMAP

<!--
**Тесты для детектирования деградации ГПСЧ/оборудования.**

Классические тесты на нормальность / uniform — это только первый фильтр. 
Они плохо ловят многие криптографически слабые дефекты.
*Более мощные подходы (именно те, что реально находят проблемы в плохих ГПСЧ):
Спектральный тест (Knuth/Marsaglia) — лучший для линейных конгруэнтных генераторов и их производных.

Тесты на линейные зависимости (overlapping words, binary rank, matrix rank)
Hamming Weight Dependencies (HWD) — вы уже упомянули, очень хороший современный тест
Graphical / визуальные тесты в нескольких измерениях (вы правильно пишете про 2D/3D проекции, «салфетки», поиск периодичности через FFT)
Тесты на линейность в GF(2) (linear complexity, approximate entropy)
Reverse engineering состояния (если период короткий — state recovery атаки)
-->